{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "vdByhZgvMVpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_input = {'text' :'',\n",
        "               'image' : ''}\n",
        "\n",
        "output_to_engine = {'engine': '',\n",
        "                    'request':\n",
        "                     {'text':'',\n",
        "                      'image':''}\n",
        "                    }\n",
        "engine_output = {'text': '', 'link': ''} # ... waiting for engines output formats to be decided\n",
        "\n",
        "output_to_user = {'answer': ''}"
      ],
      "metadata": {
        "id": "NdFpWY0Xa8K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engine Selection - Step 1\n",
        "# (format - based)"
      ],
      "metadata": {
        "id": "N5yUo0luWDhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def user_input_format(user_input):\n",
        "  if user_input['image']!='':\n",
        "    if user_input['text']=='':\n",
        "      return 'image'\n",
        "    else:\n",
        "      return 'text + image'\n",
        "  if user_input['text']!='':\n",
        "    return 'text'"
      ],
      "metadata": {
        "id": "YT6gfT4oWhuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engine Selection 2a"
      ],
      "metadata": {
        "id": "9QjlZrO2OxGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SbI_list = ['Show me images similar to this one.', 'Find me images that look like this one.']\n",
        "vQA_list = ['How many vessels does this image show?', 'Is this a rural or an urban area?']\n",
        "\n",
        "SbI_embeddings = model.encode(SbI_list)\n",
        "vQA_embeddings = model.encode(vQA_list)"
      ],
      "metadata": {
        "id": "XJxuyuO5K1RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def engine_selection_2a(text):\n",
        "  text_embeddings = [model.encode(text)]\n",
        "\n",
        "  if cosine_similarity(text_embeddings,SbI_embeddings[:]).max() > cosine_similarity(text_embeddings,vQA_embeddings[:]).max():\n",
        "    return 'SbI'\n",
        "  else:\n",
        "    return 'vQA'"
      ],
      "metadata": {
        "id": "w1-CXxi0Ozgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engine Selection 2b"
      ],
      "metadata": {
        "id": "exDuJ_nZDqeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def request_disambiguation(text):\n",
        "  disambiguation = {'need' : False,\n",
        "                    'message' : '' }\n",
        "  if ' near ' in users_input['text']:\n",
        "    disambiguation['need'] = True\n",
        "    disambiguation['message'] = \"Can you repeat your question replacing 'near' with a specific distance, please?\"\n",
        "\n",
        "  return disambiguation"
      ],
      "metadata": {
        "id": "iLRhDcf8ds7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def existence_of_geographical_object(textual_input):\n",
        "  geo_object_presense = False\n",
        "  nlp = en_core_web_sm.load()\n",
        "  doc = nlp(textual_input)\n",
        "\n",
        "  for X in doc.ents:\n",
        "    if X.label_ in ['GPE','FAC','LOC']:\n",
        "      geo_object_presense = True\n",
        "      break\n",
        "\n",
        "  return geo_object_presense"
      ],
      "metadata": {
        "id": "VCn2Bm99DvPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def engine_selection_2b():\n",
        "  if existence_of_geographical_object(users_input['text']) == True:\n",
        "    return 'EarthQA'\n",
        "  else:\n",
        "    return 'SbT'"
      ],
      "metadata": {
        "id": "IyKMHCXsNsIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chat/textual engine decision"
      ],
      "metadata": {
        "id": "l97XCXwbvpyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_list = ['Thank you!', 'This was all I wanted']\n",
        "engine_list = ['Show me images containing vessels', 'Find me Sentinel-2 satellite images that show Mount Etna, have been taken in February 2021 and have cloud cover less than 10%).']"
      ],
      "metadata": {
        "id": "y91c-4lht0Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_embeddings = model.encode(chat_list)\n",
        "engine_embeddings = model.encode(engine_list)"
      ],
      "metadata": {
        "id": "zLQ1yCravyLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def request_to_textual_engine(text):\n",
        "  # when we have a dataset of user's requests, we can implement this function via a binary classifier\n",
        "  request = False\n",
        "  # find users request's embedding\n",
        "  text_embeddings = [model.encode(text)]\n",
        "\n",
        "  if cosine_similarity(text_embeddings,chat_embeddings[:]).max() < cosine_similarity(text_embeddings,engine_embeddings[:]).max():\n",
        "    request = True\n",
        "\n",
        "  return request"
      ],
      "metadata": {
        "id": "Hz72RKa1iW-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response enhancement"
      ],
      "metadata": {
        "id": "mGysuGn1R3Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response_enhancement(engine, answer):\n",
        "#... waiting for engines output formats to be decided\n",
        "  return"
      ],
      "metadata": {
        "id": "UhEBpBNASBGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# crucial function"
      ],
      "metadata": {
        "id": "8NtXXQ6TWdpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def digital_assistant_to_engine(users_input):\n",
        "\n",
        "  #Engine Selection step 1\n",
        "  # path 'text with image'\n",
        "  if  user_input_format(users_input) == 'text + image':\n",
        "    # Engine Selection 2a\n",
        "    output_to_engine['engine'] = engine_selection_2a(users_input['text'])\n",
        "    output_to_engine['request'] = users_input\n",
        "\n",
        "  #path 'textual'\n",
        "  elif user_input_format(users_input) == 'text':\n",
        "    # decide between chat and textual engine\n",
        "    if request_to_textual_engine(users_input['text']) == False :\n",
        "      output_to_engine['engine'] = 'conversational'\n",
        "      output_to_engine['request'] = users_input\n",
        "    else:\n",
        "      # asking for clarifications\n",
        "      if request_disambiguation['need'] == True:\n",
        "        return request_disambiguation['message']\n",
        "\n",
        "      # Engine Selection 2b\n",
        "      output_to_engine['engine'] = engine_selection_2b(users_input['text'])\n",
        "      output_to_engine['request'] = users_input\n",
        "\n",
        "  return output_to_engine"
      ],
      "metadata": {
        "id": "ZeC0MacvcA3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main ()"
      ],
      "metadata": {
        "id": "bUIEJM9y4ws3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    messages = [{\"role\": \"assistant\", \"content\": \"Welcome to DA4DTE! Please enter your request.\",\n",
        "                         'image': ''}]\n",
        "    while True:\n",
        "        # read users_input file\n",
        "        messages.append({\"role\": \"user\", \"content\": users_input['text'],\n",
        "                         'image': users_input['image']})\n",
        "\n",
        "        if type(digital_assistant_to_engine(users_input))== str: # meaning that disambiguation is needed\n",
        "          answer = digital_assistant_to_engine(users_input)\n",
        "\n",
        "        else:\n",
        "          engine_input = digital_assistant_to_engine(users_input)\n",
        "          # the engine_input json file is available\n",
        "          #[... waiting for the engine to respond ...]\n",
        "          # TI reads engine_output json file\n",
        "          answer = response_enhancement(engine_output)\n",
        "          # the output_to_user file is available\n",
        "\n",
        "        messages.append({\"role\": \"assistant\", \"content\": answer, \"image\":''})"
      ],
      "metadata": {
        "id": "QUaXy56TcgW_"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}